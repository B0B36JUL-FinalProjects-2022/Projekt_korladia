{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using FinalProject\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, images = get_data(\"../data/data_alphabet.npz\")\n",
    "r = images[:,:,labels .== 0x04]\n",
    "p = Plots.heatmap(reverse(r[:,:,6], dims=1),legend = :none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose two letters & create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A', 'B', 'C', 'D', 'E', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V',\n",
    "'Y', 'Z']\n",
    "# KZ, CZ;\n",
    "# JL, EB, CV, EN, LZ- test set also separable (error 0)\n",
    "imgs, lbls, letter_counts, indices = create_work_set(alphabet, images, labels, letters = \"CZ\");\n",
    "imgs_trn, lbls_trn, imgs_tst, lbls_tst = crossval(imgs, lbls, letter_counts);\n",
    "\n",
    "# Prepare the data - compute features, add padding, etc.\n",
    "x_trn, X_trn_1, X_trn_2, lbls_trn = prep_data(imgs_trn, lbls_trn)\n",
    "x_tst, X_tst_1, X_tst_2, lbls_tst = prep_data(imgs_tst, lbls_tst)\n",
    "\n",
    "# Show data separability\n",
    "p = test_train_plot(x_trn, x_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the weights w with gradient descent and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = [-4.0,-1.0]\n",
    "res = logistic_loss(X_trn_1,lbls_trn,w_init)\n",
    "w,wt,Et = logistic_loss_gradient_descent(X_trn_1,lbls_trn,w_init)\n",
    "res_lbl = classification(X_tst_1, w, Logreg())\n",
    "err = compute_error(res_lbl, lbls_tst)\n",
    "println(\"Classification error on the test set: $(err)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = create_plot(x_trn, w, 2, \"Logistic regression - train data\")\n",
    "p2 = create_plot(x_tst, w, 2, \"Logistic regression - test data\")\n",
    "plot(p1, p2,layout=(2,1), legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result - classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification(imgs_tst, indices, res_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = [-7.0,2.0,-8.0]\n",
    "res = logistic_loss(X_trn_2,lbls_trn,w_init)\n",
    "w,wt,Et = logistic_loss_gradient_descent(X_trn_2,lbls_trn,w_init)\n",
    "res_lbl = classification(X_tst_2, w, Logreg())\n",
    "err = compute_error(res_lbl, lbls_tst)\n",
    "println(\"Classification error on the test set: $(err)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the progress of the gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = 1:size(Et)[1]\n",
    "plot(xs,Et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result - classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification(imgs_tst, indices, res_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kozinec algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_k = kozinec(X_trn_1, lbls_trn)\n",
    "res_koz = classification(X_tst_1, alpha_k, Kznc())\n",
    "alpha_p = kozinec(X_trn_1, lbls_trn, alg=Perceptron())\n",
    "res_per = classification(X_tst_1, alpha_k, Kznc())\n",
    "err_k = compute_error(res_koz, lbls_tst)\n",
    "err_p = compute_error(res_per, lbls_tst)\n",
    "# println(alpha_k)\n",
    "# println(alpha_p)\n",
    "println(\"Kozinec algorithm classification error on test data: $(err_k)\")\n",
    "println(\"Perceptron algorithm classification error on test data: $(err_p)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show test data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = create_plot(x_tst, alpha_k,2, \"Kozinec\")\n",
    "p2 = create_plot(x_tst, alpha_p,2, \"Perceptron\")\n",
    "plot(p1, p2,layout=(2,1), legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result - classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification(imgs_tst, indices, res_koz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify test data using 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_k = kozinec(X_trn_2, lbls_trn)\n",
    "res_koz = classification(X_tst_2, alpha_k, Kznc())\n",
    "alpha_p = kozinec(X_trn_2, lbls_trn, alg=Perceptron())\n",
    "res_per = classification(X_tst_2, alpha_k, Kznc())\n",
    "err_k = compute_error(res_koz, lbls_tst)\n",
    "err_p = compute_error(res_per, lbls_tst)\n",
    "# println(alpha_k)\n",
    "# println(alpha_p)\n",
    "println(\"Kozinec algorithm classification error on test data: $(err_k)\")\n",
    "println(\"Perceptron algorithm classification error on test data: $(err_p)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification(imgs_tst, indices, res_koz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inseparable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AC, MN, KP, YT\n",
    "# Best: DH, YT\n",
    "imgs, lbls, letter_counts, indices = create_work_set(alphabet, images, labels, letters = \"KP\");\n",
    "imgs_trn, lbls_trn, imgs_tst, lbls_tst = crossval(imgs, lbls, letter_counts);\n",
    "\n",
    "# Prepare the data - compute features, add padding, etc.\n",
    "x_trn, X_trn_1, X_trn_2, lbls_trn = prep_data(imgs_trn, lbls_trn)\n",
    "x_tst, X_tst_1, X_tst_2, lbls_tst = prep_data(imgs_tst, lbls_tst)\n",
    "\n",
    "# Show data inseparability\n",
    "p = test_train_plot(x_trn, x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg\n",
    "w_init = [-4.0,-1.0]\n",
    "res = logistic_loss(X_trn_1,lbls_trn,w_init)\n",
    "w,wt,Et = logistic_loss_gradient_descent(X_trn_1,lbls_trn,w_init)\n",
    "res_lbl = classification(X_trn_1, w, Logreg())\n",
    "err = compute_error(res_lbl, lbls_trn)\n",
    "# println(lbls_trn)\n",
    "# println(res_lbl)\n",
    "println(\"Classification error on the train set: $(err)\")\n",
    "\n",
    "# TEST SET\n",
    "res_lbl = classification(X_tst_1, w, Logreg())\n",
    "err = compute_error(res_lbl, lbls_tst)\n",
    "# println(lbls_trn)\n",
    "# println(res_lbl)\n",
    "println(\"Classification error on the test set: $(err)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=7\n",
    "m2 = Arctan()\n",
    "a = collect(dimension_lifting(x_trn, dims=dims, lifter = m2))\n",
    "a = reduce(vcat,transpose.(a))\n",
    "b = collect(dimension_lifting(x_tst,dims=dims, lifter = m2))\n",
    "b = reduce(vcat,transpose.(b))\n",
    "p1 = test_train_plot(x_trn, x_tst)\n",
    "indices = sortperm(x_trn)\n",
    "x_n = x_trn[indices]\n",
    "p1 = plot(p1,x_n,a[:,1:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = ones(dims+1)\n",
    "a = reshape(a,dims+1,30)\n",
    "b = reshape(b,dims+1,30)\n",
    "res = logistic_loss(a,lbls_trn,w_init)\n",
    "w,wt,Et = logistic_loss_gradient_descent(a,lbls_trn,w_init)\n",
    "res_lbl = classification(a, w, Logreg())\n",
    "err = compute_error(res_lbl, lbls_trn)\n",
    "println(\"Classification error on the train set: $(err)\")\n",
    "res_lbl = classification(b, w, Logreg())\n",
    "err = compute_error(res_lbl, lbls_tst)\n",
    "println(\"Classification error on the test set: $(err)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = a'*w\n",
    "x1 = x_trn[1:size(x_trn)[1]รท2]\n",
    "x2 = x_trn[size(x_trn)[1]รท2+1:end]\n",
    "p3 = plot(x1,zeros(15).+0.25,seriestype=:scatter, color=:pink)\n",
    "p3 = plot(p3, x2,zeros(15),seriestype=:scatter, color=:skyblue)\n",
    "indices = sortperm(x_trn)\n",
    "x_n = x_trn[indices]\n",
    "post = posteriori(res)\n",
    "post2 = posteriori(-res)\n",
    "p3 = plot(p3,x_n,post, color=:purple)\n",
    "# p3 = plot(p3,x_n,post2)\n",
    "p3 = plot(p3,x_n,ones(size(post)[1]).*0.5)\n",
    "lbls_post = [ifelse(el >= 0.5, -1, 1) for el in post]\n",
    "# println(lbls_post)\n",
    "# println(lbls_trn)\n",
    "err = compute_error(lbls_post, lbls_trn)\n",
    "println(\"Classification error on the train set: $(err)\")\n",
    "display(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "X1 = [1 1.5 2; 1 0 1]\n",
    "lbls1 = zeros(size(X1)[2])\n",
    "X2 = [-3 -2 -2.25 -1; 0 -1 -0.85 0] \n",
    "lbls2 = zeros(size(X2)[2]).+1\n",
    "X3 = [-2 -1.5 -2.75; 4 5.5 4.5]\n",
    "lbls3 = zeros(size(X3)[2]).+2\n",
    "X = hcat(X1,X2,X3)\n",
    "lbls = vcat(lbls1,lbls2,lbls3)\n",
    "#Calculate means\n",
    "m1 = get_mean(X1)\n",
    "m2 = get_mean(X2)\n",
    "m3 = get_mean(X3)\n",
    "w_init = hcat(m1,m2,m3)\n",
    "w,b = multivar(X, lbls, w_init,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(X1[1,:], X1[2,:], seriestype=:scatter, color=:skyblue)\n",
    "p = plot(p,X2[1,:], X2[2,:], seriestype=:scatter, color=:pink)\n",
    "p = plot(p,X3[1,:], X3[2,:], seriestype=:scatter, color=:lavender)\n",
    "separ3(x::Real, w::Vector, b::Real) = (w[1]*x+b)/w[2]\n",
    "w1 = w[:,1]\n",
    "w2 = w[:,2]\n",
    "w3 = w[:,3]\n",
    "xlims = extrema(X[1,:]) .+ [-0.1, 0.1]\n",
    "p = plot(p,xlims, x -> separ3(x,w1,b[1]), line = (:purple,1), legend=false)\n",
    "p = plot(p,xlims, x -> separ3(x,w2,b[2]), line = (:purple,1))\n",
    "p = plot(p,xlims, x -> separ3(x,w3,b[3]), line = (:purple,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A', 'B', 'C', 'D', 'E', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V',\n",
    "'Y', 'Z']\n",
    "\n",
    "# Choose three letters\n",
    "imgs, lbls, letter_counts, indices = create_work_set(alphabet, images, labels, letters = \"JLB\");\n",
    "imgs_trn, lbls_trn, imgs_tst, lbls_tst = crossval(imgs, lbls, letter_counts);\n",
    "\n",
    "# Prepare the data - compute features, add padding, etc.\n",
    "x_trn, X_trn_1, X_trn_2, _= prep_data(imgs_trn, lbls_trn)\n",
    "x_tst, X_tst_1, X_tst_2, _= prep_data(imgs_tst, lbls_tst)\n",
    "\n",
    "n = size(x_trn)[1]รท3\n",
    "x1 = x_trn[1:n]\n",
    "x2 = x_trn[n+1:end-n]\n",
    "x3 = x_trn[end-n+1:end]\n",
    "p = plot(x1,zeros(n),seriestype=:scatter, color=:pink)\n",
    "p = plot(p, x2,zeros(n),seriestype=:scatter, color=:purple)\n",
    "p = plot(p, x3,zeros(n),seriestype=:scatter, color=:skyblue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_trn_2[1:2,:]\n",
    "w_init, X1, X2, X3 = multi_w(X, letter_counts)\n",
    "w,b = multivar(X, lbls_trn, w_init,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(X1[1,:], X1[2,:], seriestype=:scatter, color=:skyblue)\n",
    "p = plot(p,X2[1,:], X2[2,:], seriestype=:scatter, color=:pink)\n",
    "p = plot(p,X3[1,:], X3[2,:], seriestype=:scatter, color=:lavender)\n",
    "w1 = w[:,1]\n",
    "w2 = w[:,2]\n",
    "w3 = w[:,3]\n",
    "xlims = extrema(X[1,:]) .+ [-0.1, 0.1]\n",
    "p = plot(p,xlims, x -> separ3(x,w1,b[1]), line = (:purple,1))\n",
    "p = plot(p,xlims, x -> separ3(x,w2,b[2]), line = (:purple,1))\n",
    "p = plot(p,xlims, x -> separ3(x,w3,b[3]), line = (:purple,1))\n",
    "display(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
